import streamlit as st
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.linear_model import LogisticRegression
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report
from imblearn.pipeline import Pipeline as ImbPipeline
from imblearn.over_sampling import SMOTE
import joblib
import os
import shap

# Sayfa yapÄ±landÄ±rmasÄ±
st.set_page_config(page_title="Telefon SatÄ±ÅŸ Tahmini", page_icon="ğŸ“±", layout="wide")

# Ana baÅŸlÄ±k
st.title("ğŸ“± Telefon SatÄ±ÅŸ Tahmin UygulamasÄ±")

# Sidebar oluÅŸturma
st.sidebar.title("Navigasyon")

# CSS stil tanÄ±mlamasÄ±
st.markdown("""
<style>
    .nav-button {
        background-color: #f0f2f6;
        border-radius: 10px;
        padding: 10px;
        margin: 5px 0px;
        text-align: center;
        transition: all 0.3s;
    }
    .nav-button:hover {
        background-color: #4e89ae;
        color: white;
        cursor: pointer;
    }
    .nav-button-active {
        background-color: #4e89ae;
        color: white;
        border-radius: 10px;
        padding: 10px;
        margin: 5px 0px;
        text-align: center;
    }
    .nav-icon {
        font-size: 20px;
        margin-right: 10px;
    }
</style>
""", unsafe_allow_html=True)

# Navigasyon seÃ§enekleri ve ikonlarÄ±
nav_options = {
    "Ana Sayfa": "ğŸ ",
    "Veri Analizi": "ğŸ“Š",
    "Model EÄŸitimi": "ğŸ§ ",
    "Tahmin Yap": "ğŸ”®"
}

# SeÃ§enek deÄŸiÅŸkeni iÃ§in varsayÄ±lan deÄŸer
if 'secenek' not in st.session_state:
    st.session_state.secenek = "Ana Sayfa"

# Navigasyon butonlarÄ±
for option, icon in nav_options.items():
    if st.sidebar.button(
        f"{icon} {option}", 
        key=f"nav_{option}",
        help=f"{option} sayfasÄ±na git",
        use_container_width=True,
        type="primary" if st.session_state.secenek == option else "secondary"
    ):
        st.session_state.secenek = option

# SeÃ§ilen sayfayÄ± kullan
secenek = st.session_state.secenek

# Aktif sayfa bilgisi
st.sidebar.markdown(f"<div style='text-align: center; margin-top: 20px;'>Aktif Sayfa: <b>{nav_options[secenek]} {secenek}</b></div>", unsafe_allow_html=True)

# Veri yÃ¼kleme fonksiyonu
@st.cache_data
def veri_yukle():
    try:
        df = pd.read_csv("Sales_birlesik.csv")
        return df
    except Exception as e:
        st.error(f"Veri yÃ¼klenirken hata oluÅŸtu: {e}")
        return None

# Veri Ã¶n iÅŸleme fonksiyonu
def veri_on_isleme(df):
    # Kopya oluÅŸtur
    df_temiz = df.copy()
    
    # Eksik deÄŸerleri kontrol et
    eksik_degerler = pd.DataFrame({
        'Eksik DeÄŸer SayÄ±sÄ±': df_temiz.isnull().sum(),
        'Eksik DeÄŸer OranÄ± (%)': (df_temiz.isnull().sum() / len(df_temiz) * 100).round(2)
    })
    
    # SayÄ±sal sÃ¼tunlarÄ±n doÄŸru formatta olduÄŸundan emin olma
    sayisal_sutunlar = ['Satis_Fiyati', 'Orijinal_Fiyat', 'Indirim', 'Indirim_Yuzdesi', 'Satis_Sayisi', 'Populerlik_Endeksi', 'Cikis_Tarihi']
    for sutun in sayisal_sutunlar:
        if sutun in df_temiz.columns:
            df_temiz[sutun] = pd.to_numeric(df_temiz[sutun], errors='coerce')
    
    return df_temiz, eksik_degerler

# Model eÄŸitim fonksiyonu
def model_egit(df, ozellikler, hedef, test_boyutu=0.2, random_state=42):
    # Ã–zellikler ve hedef deÄŸiÅŸkeni ayÄ±r
    X = df[ozellikler]
    y = df[hedef]
    
    # EÄŸitim ve test verisine ayÄ±r
    X_train, X_test, y_train, y_test = train_test_split(
        X, y, test_size=test_boyutu, random_state=random_state, stratify=y
    )
    
    # Veriyi Ã¶lÃ§eklendir
    scaler = StandardScaler()
    X_train_scaled = scaler.fit_transform(X_train)
    X_test_scaled = scaler.transform(X_test)
    
    # Lojistik regresyon modeli
    model = LogisticRegression(max_iter=1000, random_state=random_state)
    model.fit(X_train_scaled, y_train)
    
    # Tahmin yap
    y_pred = model.predict(X_test_scaled)
    
    # Metrikleri hesapla
    metrikler = {
        "Accuracy": accuracy_score(y_test, y_pred),
        "Precision": precision_score(y_test, y_pred),
        "Recall": recall_score(y_test, y_pred),
        "F1": f1_score(y_test, y_pred)
    }
    
    # Confusion matrix
    cm = confusion_matrix(y_test, y_pred)
    
    # SÄ±nÄ±flandÄ±rma raporu
    rapor = classification_report(y_test, y_pred, output_dict=True)
    
    return model, scaler, metrikler, cm, rapor, X_train, X_test, y_train, y_test, y_pred

# Tahmin fonksiyonu
def tahmin_yap(model, scaler, ozellikler, is_scaled=False):
    # EÄŸer deÄŸerler zaten Ã¶lÃ§eklendirilmiÅŸse, doÄŸrudan kullan
    if is_scaled:
        ozellikler_scaled = [ozellikler]
    else:
        # Ã–zellikleri Ã¶lÃ§eklendir
        ozellikler_scaled = scaler.transform([ozellikler])
    
    # Tahmin yap
    # Pipeline kullanÄ±ldÄ±ÄŸÄ±nda doÄŸrudan pipeline Ã¼zerinden tahmin yapÄ±lÄ±r
    tahmin = model.predict(ozellikler_scaled)
    tahmin_olasilik = model.predict_proba(ozellikler_scaled)[0][1]
    
    return tahmin[0], tahmin_olasilik

# Ana Sayfa
if secenek == "Ana Sayfa":
    st.write("""
    ## Telefon SatÄ±ÅŸ Tahmin UygulamasÄ±na HoÅŸ Geldiniz!
    
    Bu uygulama, telefon Ã¶zelliklerine gÃ¶re satÄ±ÅŸ tahminleri yapmak iÃ§in geliÅŸtirilmiÅŸtir.
    
    ### KullanÄ±m:
    1. **Veri Analizi**: Veri setini inceleyebilir ve gÃ¶rselleÅŸtirebilirsiniz.
    2. **Model EÄŸitimi**: Makine Ã¶ÄŸrenmesi modelini eÄŸitebilirsiniz.
    3. **Tahmin Yap**: EÄŸitilmiÅŸ model ile yeni telefonlarÄ±n satÄ±lÄ±p satÄ±lmayacaÄŸÄ±nÄ± tahmin edebilirsiniz.
    
    BaÅŸlamak iÃ§in soldaki menÃ¼den bir seÃ§enek seÃ§in.
    """)
    
    st.image("https://cdn-icons-png.flaticon.com/512/3659/3659898.png", width=300)

# Veri Analizi
elif secenek == "Veri Analizi":
    st.header("Veri Analizi")
    
    # Veriyi yÃ¼kle
    df = veri_yukle()
    if df is not None:
        # Veri Ã¶n iÅŸleme
        df_temiz, eksik_degerler = veri_on_isleme(df)
        
        # Veri seti hakkÄ±nda bilgi
        st.subheader("Veri Seti Bilgisi")
        st.write(f"Toplam {df_temiz.shape[0]} satÄ±r, {df_temiz.shape[1]} sÃ¼tun")
        
        # Veri setini gÃ¶ster
        with st.expander("Veri Setini GÃ¶ster"):
            st.dataframe(df_temiz.head(100))
        
        # Eksik deÄŸerleri gÃ¶ster
        with st.expander("Eksik DeÄŸerler"):
            st.dataframe(eksik_degerler)
        
        # Veri tipi bilgisi
        with st.expander("Veri Tipi Bilgisi"):
            buffer = pd.DataFrame(df_temiz.dtypes, columns=['Veri Tipi'])
            st.dataframe(buffer)
        
        # Ä°statistiksel Ã¶zet
        with st.expander("Ä°statistiksel Ã–zet"):
            st.dataframe(df_temiz.describe())
        
        # GÃ¶rselleÅŸtirmeler
        st.subheader("Veri GÃ¶rselleÅŸtirme")
        
        # GÃ¶rselleÅŸtirme seÃ§enekleri
        viz_option = st.selectbox(
            "GÃ¶rselleÅŸtirme seÃ§in:",
            ["SatÄ±ÅŸ Durumu DaÄŸÄ±lÄ±mÄ±", "Marka DaÄŸÄ±lÄ±mÄ±", "Fiyat DaÄŸÄ±lÄ±mÄ±", "Ä°ndirim OranÄ± DaÄŸÄ±lÄ±mÄ±", "Korelasyon Matrisi"]
        )
        
        if viz_option == "SatÄ±ÅŸ Durumu DaÄŸÄ±lÄ±mÄ±":
            fig, ax = plt.subplots(figsize=(10, 6))
            satildi_sayisi = df_temiz['Satildi'].value_counts()
            ax.pie(satildi_sayisi, labels=["SatÄ±lmadÄ±", "SatÄ±ldÄ±"], autopct='%1.1f%%', startangle=90, colors=['#ff9999','#66b3ff'])
            ax.axis('equal')  # Daire ÅŸeklinde olmasÄ± iÃ§in
            st.pyplot(fig)
            
            # SayÄ±sal deÄŸerleri gÃ¶ster
            col1, col2 = st.columns(2)
            with col1:
                st.metric("SatÄ±lan Telefon SayÄ±sÄ±", satildi_sayisi.get(1, 0))
            with col2:
                st.metric("SatÄ±lmayan Telefon SayÄ±sÄ±", satildi_sayisi.get(0, 0))
        
        elif viz_option == "Marka DaÄŸÄ±lÄ±mÄ±":
            fig, ax = plt.subplots(figsize=(12, 8))
            marka_sayisi = df_temiz['Marka'].value_counts().head(10)
            sns.barplot(x=marka_sayisi.index, y=marka_sayisi.values, ax=ax)
            plt.xticks(rotation=45)
            plt.title("En Ã‡ok Bulunan 10 Marka")
            plt.xlabel("Marka")
            plt.ylabel("SayÄ±")
            st.pyplot(fig)
        
        elif viz_option == "Fiyat DaÄŸÄ±lÄ±mÄ±":
            fig, ax = plt.subplots(figsize=(12, 6))
            sns.histplot(df_temiz['Satis_Fiyati'], bins=30, kde=True, ax=ax)
            plt.title("SatÄ±ÅŸ FiyatÄ± DaÄŸÄ±lÄ±mÄ±")
            plt.xlabel("SatÄ±ÅŸ FiyatÄ±")
            plt.ylabel("ÃœrÃ¼n SayÄ±sÄ±")
            st.pyplot(fig)
            
            # Ä°statistikler
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Ortalama Fiyat", f"{df_temiz['Satis_Fiyati'].mean():.2f}")
            with col2:
                st.metric("Minimum Fiyat", df_temiz['Satis_Fiyati'].min())
            with col3:
                st.metric("Maksimum Fiyat", df_temiz['Satis_Fiyati'].max())
        
        elif viz_option == "Ä°ndirim OranÄ± DaÄŸÄ±lÄ±mÄ±":
            fig, ax = plt.subplots(figsize=(12, 6))
            sns.histplot(df_temiz['Indirim_Yuzdesi'], bins=30, kde=True, ax=ax)
            plt.title("Ä°ndirim OranÄ± DaÄŸÄ±lÄ±mÄ±")
            plt.xlabel("Ä°ndirim OranÄ± (%)")
            plt.ylabel("ÃœrÃ¼n SayÄ±sÄ±")
            st.pyplot(fig)
            
            # Ä°statistikler
            col1, col2, col3 = st.columns(3)
            with col1:
                st.metric("Ortalama Ä°ndirim", f"{df_temiz['Indirim_Yuzdesi'].mean():.2f}%")
            with col2:
                st.metric("Minimum Ä°ndirim", f"{df_temiz['Indirim_Yuzdesi'].min():.2f}%")
            with col3:
                st.metric("Maksimum Ä°ndirim", f"{df_temiz['Indirim_Yuzdesi'].max():.2f}%")
        
        elif viz_option == "Korelasyon Matrisi":
            # SayÄ±sal sÃ¼tunlarÄ± seÃ§
            sayisal_df = df_temiz.select_dtypes(include=['float64', 'int64'])
            
            # Korelasyon matrisi
            corr_matrix = sayisal_df.corr()
            
            # GÃ¶rselleÅŸtir
            fig, ax = plt.subplots(figsize=(12, 10))
            sns.heatmap(corr_matrix, annot=True, cmap='coolwarm', fmt=".2f", ax=ax)
            plt.title("Korelasyon Matrisi")
            st.pyplot(fig)
            
            # Satildi ile en yÃ¼ksek korelasyona sahip Ã¶zellikler
            if 'Satildi' in corr_matrix.columns:
                st.subheader("'Satildi' ile En YÃ¼ksek Korelasyona Sahip Ã–zellikler")
                satildi_corr = corr_matrix['Satildi'].drop('Satildi').abs().sort_values(ascending=False)
                
                fig, ax = plt.subplots(figsize=(10, 6))
                sns.barplot(x=satildi_corr.values, y=satildi_corr.index, ax=ax)
                plt.title("'Satildi' ile Korelasyon")
                plt.xlabel("Korelasyon KatsayÄ±sÄ± (Mutlak DeÄŸer)")
                st.pyplot(fig)

# Model EÄŸitimi
elif secenek == "Model EÄŸitimi":
    st.header("Model EÄŸitimi")
    
    # Veriyi yÃ¼kle
    df = veri_yukle()
    if df is not None:
        # Veri Ã¶n iÅŸleme
        df_temiz, _ = veri_on_isleme(df)
       
        with st.spinner("Model eÄŸitimi hazÄ±rlanÄ±yor..."):
            # Ã–zellikler ve hedef deÄŸiÅŸkeni ayÄ±rma
            # Ã–lÃ§eklendirilmiÅŸ sÃ¼tunlarÄ± kullanacaÄŸÄ±z
            olcekli_sutunlar = [col for col in df_temiz.columns if col.endswith('_Scaled')]
            
            # Kategorik sÃ¼tunlarÄ± da ekleyelim
            kategorik_sutunlar = [col for col in df_temiz.columns if col.endswith('_Encoded')]
            if not kategorik_sutunlar:
                st.info("KodlanmÄ±ÅŸ kategorik sÃ¼tunlar bulunamadÄ±. Kategorik sÃ¼tunlar iÃ§in LabelEncoder uygulanacak.")
                
                # Kategorik sÃ¼tunlarÄ± kodla
                for sutun in ['Marka', 'Model', 'Renk']:
                    if sutun in df_temiz.columns:
                        le = LabelEncoder()
                        df_temiz[sutun + '_Encoded'] = le.fit_transform(df_temiz[sutun].astype(str))
                        kategorik_sutunlar.append(sutun + '_Encoded')
            
            # Ã–nemli sayÄ±sal sÃ¼tunlar
            sayisal_sutunlar = ['Bellek', 'Depolama', 'Puan', 'Satis_Fiyati', 'Orijinal_Fiyat', 'Indirim', 
                               'Indirim_Yuzdesi', 'Satis_Sayisi', 'Populerlik_Endeksi']
            
            # Mevcut sayÄ±sal sÃ¼tunlarÄ± kontrol et
            mevcut_sayisal_sutunlar = [col for col in sayisal_sutunlar if col in df_temiz.columns]
            
            # TÃ¼m Ã¶zellikleri birleÅŸtir
            tum_ozellikler = olcekli_sutunlar + kategorik_sutunlar + mevcut_sayisal_sutunlar
            
            # KullanÄ±cÄ±ya Ã¶zellik seÃ§me imkanÄ± ver
            secilen_ozellikler = st.multiselect(
                "KullanÄ±lacak Ã¶zellikleri seÃ§in:",
                options=tum_ozellikler,
                default=tum_ozellikler[:min(8, len(tum_ozellikler))]  # En fazla 8 Ã¶zellik varsayÄ±lan olarak seÃ§
            )
        
        if len(secilen_ozellikler) > 0:
            # Model eÄŸitimi baÅŸlat
            if st.button("Modeli EÄŸit"):
                with st.spinner("Model eÄŸitiliyor..."):
                    # Ã–zellikler ve hedef deÄŸiÅŸkeni ayÄ±r
                    X = df_temiz[secilen_ozellikler]
                    y = df_temiz['Satildi']
                    
                    # EÄŸitim ve test setlerine ayÄ±r
                    X_train, X_test, y_train, y_test = train_test_split(
                        X, y, test_size=0.2, random_state=42, stratify=y
                    )
                    
                    st.text(f'EÄŸitim seti boyutu: {X_train.shape}')
                    st.text(f'Test seti boyutu: {X_test.shape}')
                    
                    # Ã–nceden belirlenmiÅŸ en iyi parametreler
                    best_params = {
                        'classifier__class_weight': 'balanced_subsample',
                        'classifier__max_depth': 20,
                        'classifier__min_samples_leaf': 1,
                        'classifier__min_samples_split': 2,
                        'classifier__n_estimators': 100
                    }
                    
                    st.text('Ã–nceden belirlenmiÅŸ en iyi parametreler kullanÄ±lÄ±yor:')
                    st.text(f'En iyi parametreler: {best_params}')
                    
                    # SMOTE ile dengeleme ve model eÄŸitimi iÃ§in pipeline oluÅŸturma
                    # Ã–nceden belirlenmiÅŸ parametrelerle doÄŸrudan modeli oluÅŸturuyoruz
                    best_model = ImbPipeline([
                        ('smote', SMOTE(random_state=42)),
                        ('classifier', RandomForestClassifier(
                            n_estimators=best_params['classifier__n_estimators'],
                            max_depth=best_params['classifier__max_depth'],
                            min_samples_split=best_params['classifier__min_samples_split'],
                            min_samples_leaf=best_params['classifier__min_samples_leaf'],
                            class_weight=best_params['classifier__class_weight'],
                            random_state=42
                        ))
                    ])
                    
                    # Modeli eÄŸit
                    best_model.fit(X_train, y_train)
                    y_pred = best_model.predict(X_test)
                    
                    # Metrikleri hesapla
                    metrikler = {
                        "Accuracy": accuracy_score(y_test, y_pred),
                        "Precision": precision_score(y_test, y_pred),
                        "Recall": recall_score(y_test, y_pred),
                        "F1": f1_score(y_test, y_pred)
                    }
                    
                    # StandardScaler oluÅŸtur ve verileri Ã¶lÃ§eklendir
                    scaler = StandardScaler()
                    X_train_scaled = scaler.fit_transform(X_train)
                    X_test_scaled = scaler.transform(X_test)
                    
                    # Modeli kaydet
                    if not os.path.exists('model'):
                        os.makedirs('model')
                    joblib.dump(best_model, 'model/telefon_satis_model.pkl')
                    joblib.dump(scaler, 'model/telefon_satis_scaler.pkl')
                    joblib.dump(secilen_ozellikler, 'model/telefon_satis_ozellikler.pkl')
                    
                    st.success("Model baÅŸarÄ±yla eÄŸitildi ve kaydedildi!")
                    
                    # Metrikleri gÃ¶ster
                    st.subheader("Model PerformansÄ±")
                    col1, col2, col3, col4 = st.columns(4)
                    col1.metric("Accuracy", f"{metrikler['Accuracy']:.4f}")
                    col2.metric("Precision", f"{metrikler['Precision']:.4f}")
                    col3.metric("Recall", f"{metrikler['Recall']:.4f}")
                    col4.metric("F1 Score", f"{metrikler['F1']:.4f}")
                    
                    # SÄ±nÄ±flandÄ±rma raporu
                    st.subheader("SÄ±nÄ±flandÄ±rma Raporu")
                    rapor = classification_report(y_test, y_pred, output_dict=True)
                    rapor_df = pd.DataFrame(rapor).transpose()
                    st.dataframe(rapor_df)
                    
                    # Confusion Matrix
                    st.subheader("Confusion Matrix")
                    cm = confusion_matrix(y_test, y_pred)
                    fig, ax = plt.subplots(figsize=(8, 6))
                    sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", ax=ax)
                    plt.xlabel("Tahmin Edilen")
                    plt.ylabel("GerÃ§ek")
                    plt.title("Confusion Matrix")
                    st.pyplot(fig)
                    

# Tahmin Yap
elif secenek == "Tahmin Yap":
    st.header("Tahmin Yap")
    
    # Model dosyalarÄ±nÄ± kontrol et
    model_path = 'model/telefon_satis_model.pkl'
    scaler_path = 'model/telefon_satis_scaler.pkl'
    ozellikler_path = 'model/telefon_satis_ozellikler.pkl'
    
    if os.path.exists(model_path) and os.path.exists(scaler_path) and os.path.exists(ozellikler_path):
        # Model ve ilgili dosyalarÄ± yÃ¼kle
        model = joblib.load(model_path)
        scaler = joblib.load(scaler_path)
        secilen_ozellikler = joblib.load(ozellikler_path)
        
        st.subheader("Telefon Ã–zelliklerini Girin")
        
        # Veriyi yÃ¼kle (Ã¶zellik aralÄ±klarÄ±nÄ± belirlemek iÃ§in)
        df = veri_yukle()
        if df is not None:
            # Veri Ã¶n iÅŸleme
            df_temiz, _ = veri_on_isleme(df)
            
            # KullanÄ±cÄ± giriÅŸleri iÃ§in sÃ¼tunlar oluÅŸtur
            ozellik_degerleri = []
            
            # Her Ã¶zellik iÃ§in giriÅŸ alanÄ± oluÅŸtur
            col1, col2 = st.columns(2)
            
            for i, ozellik in enumerate(secilen_ozellikler):
                # Ã–lÃ§eklendirilmiÅŸ Ã¶zellikler iÃ§in kullanÄ±cÄ±nÄ±n belirttiÄŸi aralÄ±klarÄ± kullan
                if ozellik.endswith('_Scaled'):
                    # KullanÄ±cÄ±nÄ±n belirttiÄŸi deÄŸer aralÄ±klarÄ±nÄ± kullan
                    if ozellik == 'Satis_Fiyati_Scaled':
                        min_deger = 0.00
                        max_deger = 6.00
                    elif ozellik == 'Satis_Sayisi_Scaled':
                        min_deger = 0.00
                        max_deger = 1.00
                    elif ozellik == 'Bellek_Scaled':
                        min_deger = 0.00
                        max_deger = 10.00
                    elif ozellik == 'Marka_Encoded':
                        min_deger = 0.00
                        max_deger = 16.00
                    elif ozellik == 'Orijinal_Fiyat_Scaled':
                        min_deger = 0.00
                        max_deger = 5.00
                    elif ozellik == 'Populerlik_Endeksi_Scaled':
                        min_deger = 0.00
                        max_deger = 1.00
                    elif ozellik == 'Depolama_Scaled':
                        min_deger = 0.00
                        max_deger = 256.00
                    elif ozellik == 'Model_Encoded':
                        min_deger = 0.00
                        max_deger = 16.00
                    else:
                        min_deger = -3.0  # Standart normal daÄŸÄ±lÄ±m iÃ§in tipik minimum deÄŸer
                        max_deger = 3.0   # Standart normal daÄŸÄ±lÄ±m iÃ§in tipik maksimum deÄŸer
                    
                    ortalama = (min_deger + max_deger) / 2  # Ortalama deÄŸeri aralÄ±ÄŸÄ±n ortasÄ± olarak ayarla
                    adim = (max_deger - min_deger) / 100     # AdÄ±m boyutunu aralÄ±ÄŸa gÃ¶re ayarla
                else:
                    # Normal Ã¶zellikler iÃ§in veri setinden deÄŸerleri al
                    min_deger = float(df_temiz[ozellik].min())
                    max_deger = float(df_temiz[ozellik].max())
                    ortalama = float(df_temiz[ozellik].mean())
                    adim = (max_deger - min_deger) / 100
                
                # KullanÄ±cÄ± dostu etiketler oluÅŸtur
                etiket = ozellik
                if ozellik == 'Satis_Fiyati_Scaled':
                    etiket = 'SatÄ±ÅŸ FiyatÄ±'
                elif ozellik == 'Satis_Sayisi_Scaled':
                    etiket = 'SatÄ±ÅŸ SayÄ±sÄ±'
                elif ozellik == 'Bellek_Scaled':
                    etiket = 'RAM Bellek (GB)'
                elif ozellik == 'Marka_Encoded':
                    etiket = 'Marka'
                elif ozellik == 'Orijinal_Fiyat_Scaled':
                    etiket = 'Orijinal Fiyat'
                elif ozellik == 'Populerlik_Endeksi_Scaled':
                    etiket = 'PopÃ¼lerlik Endeksi'
                elif ozellik == 'Depolama_Scaled':
                    etiket = 'Depolama AlanÄ± (GB)'
                elif ozellik == 'Model_Encoded':
                    etiket = 'Model'
                
                # GiriÅŸ alanÄ± oluÅŸtur
                if i % 2 == 0:
                    with col1:
                        deger = st.slider(
                            f"{etiket}:",
                            min_deger,
                            max_deger,
                            ortalama,
                            adim
                        )
                        ozellik_degerleri.append(deger)
                else:
                    with col2:
                        deger = st.slider(
                            f"{etiket}:",
                            min_deger,
                            max_deger,
                            ortalama,
                            adim
                        )
                        ozellik_degerleri.append(deger)
            
            # Tahmin yap
            if st.button("Tahmin Yap"):
                with st.spinner("Tahmin yapÄ±lÄ±yor..."):
                    # Ã–lÃ§eklendirilmiÅŸ deÄŸerler iÃ§in is_scaled=True parametresi ile tahmin yap
                    # EÄŸer Ã¶zellik adÄ± _Scaled ile bitiyorsa, deÄŸerler zaten Ã¶lÃ§eklendirilmiÅŸtir
                    is_scaled = any(ozellik.endswith('_Scaled') for ozellik in secilen_ozellikler)
                    tahmin, tahmin_olasilik = tahmin_yap(model, scaler, ozellik_degerleri, is_scaled=is_scaled)
                    
                    # SonuÃ§larÄ± gÃ¶ster
                    st.subheader("Tahmin Sonucu")
                    
                    # GÃ¶rsel gÃ¶sterge
                    if tahmin == 1:
                        st.success("Bu telefon satÄ±labilir! ğŸ“±âœ…")
                        st.balloons()
                    else:
                        st.error("Bu telefon satÄ±lmayabilir! ğŸ“±âŒ")
                    
                    # OlasÄ±lÄ±k gÃ¶ster
                    st.write(f"SatÄ±lma olasÄ±lÄ±ÄŸÄ±: {tahmin_olasilik:.2%}")
                    
                    # OlasÄ±lÄ±k gÃ¶stergesi
                    st.progress(tahmin_olasilik)
                    
                    # Girilen deÄŸerleri kullanÄ±cÄ± dostu etiketlerle gÃ¶ster
                    st.subheader("Girilen DeÄŸerler")
                    
                    # KullanÄ±cÄ± dostu etiketleri oluÅŸtur
                    kullanici_dostu_etiketler = []
                    for oz in secilen_ozellikler:
                        if oz == 'Satis_Fiyati_Scaled':
                            kullanici_dostu_etiketler.append('SatÄ±ÅŸ FiyatÄ±')
                        elif oz == 'Satis_Sayisi_Scaled':
                            kullanici_dostu_etiketler.append('SatÄ±ÅŸ SayÄ±sÄ±')
                        elif oz == 'Bellek_Scaled':
                            kullanici_dostu_etiketler.append('RAM Bellek (GB)')
                        elif oz == 'Marka_Encoded':
                            kullanici_dostu_etiketler.append('Marka')
                        elif oz == 'Orijinal_Fiyat_Scaled':
                            kullanici_dostu_etiketler.append('Orijinal Fiyat')
                        elif oz == 'Populerlik_Endeksi_Scaled':
                            kullanici_dostu_etiketler.append('PopÃ¼lerlik Endeksi')
                        elif oz == 'Depolama_Scaled':
                            kullanici_dostu_etiketler.append('Depolama AlanÄ± (GB)')
                        elif oz == 'Model_Encoded':
                            kullanici_dostu_etiketler.append('Model')
                        else:
                            kullanici_dostu_etiketler.append(oz)
                    
                    girdi_df = pd.DataFrame([ozellik_degerleri], columns=kullanici_dostu_etiketler)
                    st.dataframe(girdi_df)
        else:
            st.error("Veri yÃ¼klenemedi. LÃ¼tfen veri dosyasÄ±nÄ± kontrol edin.")
    else:
        st.warning("HenÃ¼z eÄŸitilmiÅŸ bir model bulunamadÄ±. LÃ¼tfen Ã¶nce 'Model EÄŸitimi' sekmesinden bir model eÄŸitin.")